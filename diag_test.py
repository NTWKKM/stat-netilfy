# diag_test.py

import pandas as pd
import numpy as np
import scipy.stats as stats
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt
import io, base64 

def calculate_descriptive(df, col):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô"""
    if col not in df.columns: return None, "Column not found"
    
    data = df[col].dropna()
    try:
        # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
        num_data = pd.to_numeric(data, errors='raise')
        is_numeric = True
    except:
        is_numeric = False
        
    if is_numeric:
        desc = num_data.describe()
        return pd.DataFrame({
            "Statistic": ["Count", "Mean", "SD", "Median", "Min", "Max", "Q1 (25%)", "Q3 (75%)"],
            "Value": [
                f"{desc['count']:.0f}",
                f"{desc['mean']:.4f}",
                f"{desc['std']:.4f}",
                f"{desc['50%']:.4f}",
                f"{desc['min']:.4f}",
                f"{desc['max']:.4f}",
                f"{desc['25%']:.4f}",
                f"{desc['75%']:.4f}"
            ]
        }), None
    else:
        # Categorical
        counts = data.value_counts()
        percent = data.value_counts(normalize=True) * 100
        return pd.DataFrame({
            "Category": counts.index,
            "Count": counts.values,
            "Percentage (%)": percent.values
        }).sort_values("Count", ascending=False), None

def calculate_chi2(df, col1, col2):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Chi-square ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏±‡πâ‡∏á RR, ARR, NNT ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ Count ‡πÅ‡∏•‡∏∞ Percent"""
    if col1 not in df.columns or col2 not in df.columns: 
        return None, {"error": "Columns not found"}
    
    data = df[[col1, col2]].dropna()
    
    # Contingency Table (Frequency Count)
    tab_raw = pd.crosstab(data[col1], data[col2], margins=True, margins_name="Total")
    
    # --- Chi-square Calculation ---
    results = {}
    
    # ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏¢‡∏Å Chi-square ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å margins
    tab_for_chi2 = pd.crosstab(data[col1], data[col2]) 
    
    try:
        chi2, p, dof, ex = stats.chi2_contingency(tab_for_chi2)
        results['chi2_msg'] = f"Chi-square statistic: {chi2:.4f}, p-value: {p:.4f}, df: {dof}"
        results['p_value'] = p
    except Exception as e:
        results['chi2_msg'] = f"Chi-square calculation error: {str(e)}"
        
    # --- RR / ARR / NNT Calculation (Only for 2x2 table) ---
    if tab_for_chi2.shape == (2, 2):
        tab_arr = tab_for_chi2.values 
        a, b = tab_arr[0, 0], tab_arr[0, 1] 
        c, d = tab_arr[1, 0], tab_arr[1, 1] 
        
        N_exp = a + b 
        N_unexp = c + d 
        
        R_exp = a / N_exp if N_exp > 0 else 0 
        R_unexp = c / N_unexp if N_unexp > 0 else 0 
        
        if N_exp > 0 and N_unexp > 0:
            RR = R_exp / R_unexp if R_unexp > 0 else np.inf
            RD = R_exp - R_unexp
            NNT = 1 / abs(RD) if RD != 0 and abs(RD) <= 1 else np.inf
            OR = (a * d) / (b * c) if b != 0 and c != 0 else np.inf
            
            results['Is_2x2'] = True
            results['RR'] = RR
            results['RD'] = RD
            results['NNT'] = NNT
            results['OR'] = OR
            results['R_exp'] = R_exp
            results['R_unexp'] = R_unexp
            results['R_exp_label'] = tab_for_chi2.index[0]
            results['R_unexp_label'] = tab_for_chi2.index[1]
            results['Event_label'] = tab_for_chi2.columns[0]
        else:
            results['RR'] = np.nan
            results['NNT'] = np.nan
            results['RD'] = np.nan
            results['Is_2x2'] = True
            
    # --- Formatting Display Table (Count, Row %, Total %) ---
    
    # 1. Calculate Row Percentages (Horizontal %)
    tab_row_percent = pd.crosstab(data[col1], data[col2], normalize='index', margins=True, margins_name="Total") * 100
    
    # 2. Calculate Total Percentages (Grand Total %)
    tab_total_percent = pd.crosstab(data[col1], data[col2], normalize='all', margins=True, margins_name="Total") * 100
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á Display Final
    col_names = tab_raw.columns.tolist() 
    index_names = tab_raw.index.tolist() 
    
    display_tab_data = []
    
    for row_name in index_names:
        row_data = [] 
        
        for col_name in col_names:
            count = tab_raw.loc[row_name, col_name]
            total_pct = tab_total_percent.loc[row_name, col_name]

            if col_name == 'Total' and row_name == 'Total':
                # Grand Total Cell: ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Count ‡πÅ‡∏•‡∏∞ Total %
                row_pct = 100.0
                cell_content = f"{count} / ({total_pct:.1f}%)"
            elif col_name == 'Total':
                # Row Marginal Total Cell: ‡πÅ‡∏™‡∏î‡∏á Count ‡πÅ‡∏•‡∏∞ Total %
                row_pct = 100.0
                cell_content = f"{count} ({row_pct:.1f}%) / ({total_pct:.1f}%)"
            else:
                # Normal Data Cell: ‡πÅ‡∏™‡∏î‡∏á Count, Row %, Total %
                row_pct = tab_row_percent.loc[row_name, col_name]
                cell_content = f"{count} ({row_pct:.1f}%) / ({total_pct:.1f}%)"
            
            row_data.append(cell_content)
            
        display_tab_data.append([row_name] + row_data) 

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
    display_tab = pd.DataFrame(display_tab_data, columns=[col1] + col_names)
    display_tab = display_tab.set_index(col1)
        
    return display_tab, results
    
# --- ROC & AUC FUNCTIONS ---

def auc_ci_hanley_mcneil(auc, n1, n2):
    """
    Hanley & McNeil (1982) method for AUC Variance (Parametric/Binomial assumption)
    n1: positive cases, n2: negative cases
    """
    q1 = auc / (2 - auc)
    q2 = 2 * (auc**2) / (1 + auc)
    
    se_auc = np.sqrt(((auc * (1 - auc)) + (n1 - 1)*(q1 - auc**2) + (n2 - 1)*(q2 - auc**2)) / (n1 * n2))
    lower = auc - 1.96 * se_auc
    upper = auc + 1.96 * se_auc
    return lower, upper, se_auc

def auc_ci_delong(y_true, y_scores):
    """
    DeLong et al. (1988) method for AUC Variance (Non-parametric)
    Ref: Fast implementation logic
    """
    y_true = np.array(y_true)
    y_scores = np.array(y_scores)
    
    # Sort by score
    desc_score_indices = np.argsort(y_scores, kind="mergesort")[::-1]
    y_scores = y_scores[desc_score_indices]
    y_true = y_true[desc_score_indices]
    
    distinct_value_indices = np.where(np.diff(y_scores))[0]
    threshold_idxs = np.r_[distinct_value_indices, y_true.size - 1]
    
    tps = np.cumsum(y_true)[threshold_idxs]
    fps = 1 + threshold_idxs - tps
    
    n_pos = tps[-1]
    n_neg = fps[-1]
    
    if n_pos == 0 or n_neg == 0:
        return np.nan, np.nan, np.nan # Cannot calc
    
    auc = roc_auc_score(y_true, y_scores)
    
    # DeLong Covariance Calculation
    # Compute V10 (X) and V01 (Y)
    
    pos_scores = y_scores[y_true == 1]
    neg_scores = y_scores[y_true == 0]
    
    def compute_mid_rank(x):
        """Helper to get mid-ranks"""
        argsort = np.argsort(x)
        ranks = np.empty_like(argsort)
        ranks[argsort] = np.arange(len(x))
        return (ranks + 1) # dummy, actual logic below
        
    # Faster vectorization for V10, V01
    # Concatenate all scores to rank them
    all_scores = np.concatenate([pos_scores, neg_scores])
    all_labels = np.concatenate([np.ones(len(pos_scores)), np.zeros(len(neg_scores))])
    
    # Rank (with average for ties)
    order = np.argsort(all_scores)
    ranks = stats.rankdata(all_scores) # 1-based, average ties
    
    # Sum of ranks for positives
    # AUC = (Sum(R_pos) - n_pos(n_pos+1)/2 ) / (n_pos * n_neg)
    
    # DeLong variance components
    # We need empirical Probabilities
    
    # V10: For each positive, what fraction of negatives is it greater than?
    v10 = []
    for p in pos_scores:
        v10.append( (np.sum(p > neg_scores) + 0.5*np.sum(p == neg_scores)) / n_neg )
    v10 = np.array(v10)
    
    # V01: For each negative, what fraction of positives is it smaller than?
    v01 = []
    for n in neg_scores:
        v01.append( (np.sum(pos_scores > n) + 0.5*np.sum(pos_scores == n)) / n_pos )
    v01 = np.array(v01)
    
    # Variance
    s10 = np.var(v10, ddof=1)
    s01 = np.var(v01, ddof=1)
    
    var_auc = (s10 / n_pos) + (s01 / n_neg)
    se_auc = np.sqrt(var_auc)
    
    return auc - 1.96*se_auc, auc + 1.96*se_auc, se_auc


def analyze_roc(df, truth_col, score_col, method='delong', pos_label_user=None):
    """Main ROC Analysis"""
    data = df[[truth_col, score_col]].dropna()
    y_true_raw = data[truth_col]
    y_score = pd.to_numeric(data[score_col], errors='coerce').dropna()
    # Align indices
    y_true_raw = y_true_raw.loc[y_score.index]
    
    unique_vals = y_true_raw.nunique()
    if unique_vals != 2:
        return None, "Outcome must have exactly 2 classes.", None, None 

    # üü¢ START: Manual Encoding based on user input (Overriding LabelEncoder)
    if pos_label_user is None:
        # ‡∏Ñ‡∏ß‡∏£‡∏ñ‡∏π‡∏Å‡∏î‡∏±‡∏Å‡∏à‡∏±‡∏ö‡πÉ‡∏ô app.py ‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡πÑ‡∏ß‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
        return None, "Positive label (pos_label) must be specified for binary outcome.", None, None
        
    # Map user's selected label to 1, and the other label to 0
    # ‡πÉ‡∏ä‡πâ str() ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö String ‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏à‡∏≤‡∏Å Selectbox
    if str(y_true_raw.iloc[0]) not in [str(x) for x in y_true_raw.unique()]:
        # ‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÅ‡∏•‡πâ‡∏ß ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°
        # ‡πÅ‡∏ï‡πà‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ str() ‡πÉ‡∏ô selectbox ‡πÅ‡∏•‡∏∞‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏ô‡∏µ‡πâ‡∏à‡∏∂‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
        pass
        
    # ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ Negative label ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏≠‡∏¢‡∏π‡πà
    all_labels_raw = [str(x) for x in y_true_raw.unique()]
    neg_label_raw = [lab for lab in all_labels_raw if lab != pos_label_user][0]
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô 0/1
    y_true = np.where(y_true_raw.astype(str) == pos_label_user, 1, 0)
    
    # Cast y_true back to pd.Series for alignment/indexing safety
    y_true = pd.Series(y_true, index=y_true_raw.index)
    # üü¢ END: Manual Encoding
        
    # 1. Calculate AUC
    fpr, tpr, thresholds = roc_curve(y_true, y_score)
    auc_val = roc_auc_score(y_true, y_score)
    
    n1 = sum(y_true == 1)
    n0 = sum(y_true == 0)
    
    # 2. Calculate CI
    if method == 'delong':
        ci_lower, ci_upper, se = auc_ci_delong(y_true.values, y_score.values)
        method_name = "DeLong et al."
    else:
        # Binomial Exact / Hanley McNeil
        ci_lower, ci_upper, se = auc_ci_hanley_mcneil(auc_val, n1, n0)
        method_name = "Hanley & McNeil (Parametric/Binomial)"
        
    ci_lower = max(0.0, ci_lower)
    ci_upper = min(1.0, ci_upper)

    # üü¢ START: Calculate P-value for AUC (H0: AUC = 0.5)
    p_value_auc = np.nan
    try:
        if se > 0:
            # Z = (AUC - 0.5) / SE
            Z_score = (auc_val - 0.5) / se
            # Two-tailed P-value from Standard Normal Distribution
            p_value_auc = stats.norm.sf(abs(Z_score)) * 2 
        else:
            # Perfect separation (AUC=1 or 0), P-value is effectively 0
            p_value_auc = 0.0 
    except:
        p_value_auc = np.nan
    # üü¢ END: Calculate P-value for AUC
    
    # 3. Youden Index
    # J = Sensitivity + Specificity - 1 = TPR + (1 - FPR) - 1 = TPR - FPR
    j_scores = tpr - fpr
    best_idx = np.argmax(j_scores)
    youden_j = j_scores[best_idx]
    best_thresh = thresholds[best_idx]
    best_sens = tpr[best_idx]
    best_spec = 1 - fpr[best_idx]
    
    stats_res = {
        "AUC": auc_val,
        "SE": se,
        "95% CI Lower": ci_lower,
        "95% CI Upper": ci_upper,
        "Method": method_name,
        "P-value (H0: AUC=0.5)": p_value_auc, # üü¢ ADDED P-VALUE HERE
        "Youden Index (J)": youden_j,
        "Best Cut-off": best_thresh,
        "Sensitivity": best_sens,
        "Specificity": best_spec,
        "N (Positive)": n1,
        "N (Negative)": n0,
        "Positive Label": pos_label_user, 
        "Negative Label": neg_label_raw    
    }
    
    # 4. Plot
    fig, ax = plt.subplots(figsize=(6, 5))
    ax.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_val:.3f})')
    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    
    # Mark Youden point
    ax.plot(1-best_spec, best_sens, 'ro', label=f'Best Cut-off ({best_thresh:.2f})')
    
    ax.set_xlim([0.0, 1.0])
    ax.set_ylim([0.0, 1.05])
    ax.set_xlabel('False Positive Rate (1 - Specificity)')
    ax.set_ylabel('True Positive Rate (Sensitivity)')
    ax.set_title(f'ROC Curve: {score_col} vs {truth_col}')
    ax.legend(loc="lower right")
    ax.grid(alpha=0.3)

    # 5. Create Coordinates DataFrame for detailed table (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ)
    coords_df = pd.DataFrame({
        'Threshold': thresholds,
        'Sensitivity (TPR)': tpr,
        'Specificity': 1 - fpr,
        '1 - Specificity (FPR)': fpr,
        'Youden J': tpr - fpr
    }).sort_values('Threshold', ascending=False).reset_index(drop=True)
    coords_df['Threshold'] = coords_df['Threshold'].round(4)
    coords_df = coords_df.round(4)
    
    return stats_res, None, fig, coords_df # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏´‡πâ return 4 ‡∏Ñ‡πà‡∏≤

def generate_report(title, elements):
    """Generates a simple HTML report based on a list of elements (text, plot, table)."""
    
    # --- CSS Styling (Fixed to use Streamlit CSS variables for theme compatibility) ---
    css_style = """
    <style>
        body { font-family: 'Segoe UI', sans-serif; padding: 20px; background-color: var(--secondary-background-color); margin: 0; color: var(--text-color); }
        .report-container { 
            background: var(--background-color); 
            border-radius: 8px; 
            box-shadow: 0 4px 15px rgba(0,0,0,0.05); 
            padding: 20px;
            width: 100%; 
            box-sizing: border-box;
            margin-bottom: 20px;
        }
        h2 { color: var(--primary-color); border-bottom: 2px solid var(--border-color); padding-bottom: 10px; }
        h4 { color: var(--text-color); margin-top: 25px; margin-bottom: 10px; }
        table { 
            width: 100%; 
            border-collapse: collapse; 
            font-family: 'Segoe UI', sans-serif; 
            font-size: 0.9em;
        }
        th, td { 
            padding: 10px 15px; 
            border: 1px solid var(--border-color);
            vertical-align: top;
            text-align: left;
        }
        th {
            background-color: var(--primary-color); 
            color: var(--text-color-inverted);
            font-weight: 600;
        }
        tr:nth-child(even) td { background-color: var(--secondary-background-color); }
        .alert { background-color: var(--secondary-background-color); color: var(--warning-color); padding: 10px; border: 1px solid var(--border-color); border-radius: 5px; margin-bottom: 15px; }
        
        .report-table th, .report-table td { text-align: center; } 
        .report-table th:first-child, .report-table td:first-child { text-align: left; }
        
        .report-footer {
            text-align: right;
            font-size: 0.75em;
            color: var(--text-color);
            margin-top: 20px;
            border-top: 1px dashed var(--border-color);
            padding-top: 10px;
        }
    </style>
    """
    
    html = f"<!DOCTYPE html><html><head>{css_style}</head><body>"
    html += f"<div class='report-container'><h2>{title}</h2>"
    
    for element in elements:
        element_type = element['type']
        data = element['data']
        header = element.get('header', '')
        
        if header:
            html += f"<h4>{header}</h4>"
            
        if element_type == 'text':
            html += f"<p>{data}</p>"
        elif element_type == 'table':
            # Handle standard table (e.g., Key Statistics, Descriptive)
            include_index = not data.columns.contains('Category') and not data.columns.contains('Statistic')
            html += data.to_html(index=include_index, classes='report-table')
            
        # üü¢ NEW: Handle Contingency Table with Two-Level Header
        elif element_type == 'contingency_table':
            # DataFrame should have V1 as index and V2 levels + 'Total' as columns
            df_html = data.to_html(index=True, classes='report-table', header=False) # ‡∏™‡∏£‡πâ‡∏≤‡∏á HTML ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ Header
            
            # 1. ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå (0, 1, Total) ‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠ Index (Exposure)
            col_names_raw = data.columns.tolist()
            index_name = data.index.name
            outcome_col_name = element.get('outcome_col', 'Outcome')
            
            # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Header ‡∏™‡∏≠‡∏á‡∏ä‡∏±‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ HTML
            
            # Row 1: Merge cells for Outcome_Disease and Total
            # (First TH is for Exposure/Row Variable, colspan should cover all data columns)
            header_row1 = f"<tr>"
            # Th ‡πÅ‡∏£‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Index (V1)
            header_row1 += f"<th rowspan='2' class='report-table' style='text-align: left;'>{index_name}</th>" 
            # Th ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠ Merge Cells ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ä‡∏∑‡πà‡∏≠ Outcome (‡∏£‡∏ß‡∏° Total ‡∏î‡πâ‡∏ß‡∏¢)
            header_row1 += f"<th colspan='{len(col_names_raw)}' class='report-table'>{outcome_col_name}</th>" 
            header_row1 += f"</tr>"
            
            # Row 2: Actual Outcome Levels (0, 1, Total)
            header_row2 = f"<tr>"
            for col_name in col_names_raw:
                 # ‡πÅ‡∏™‡∏î‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∞‡∏î‡∏±‡∏ö (0, 1, Total)
                 header_row2 += f"<th class='report-table'>{col_name}</th>"
            header_row2 += f"</tr>"
            
            # 3. ‡∏ô‡∏≥ Header ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏á‡πÑ‡∏õ‡πÉ‡∏™‡πà‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á HTML
            table_start_tag = df_html.split('<thead>')[0]
            table_end_tag = df_html.split('</thead>')[1]
            
            custom_header = f"<thead>{header_row1}{header_row2}</thead>"
            
            html += table_start_tag + custom_header + table_end_tag


        elif element_type == 'plot':
            # Save matplotlib figure to a string buffer and convert to base64 for embedding
            buf = io.BytesIO()
            if isinstance(data, plt.Figure):
                data.savefig(buf, format='png')
                plt.close(data) # Close the figure to free memory
                data_uri = base64.b64encode(buf.getvalue()).decode('utf-8')
                buf.close()
                html += f'<img src="data:image/png;base64,{data_uri}" style="max-width: 100%; height: auto; display: block; margin: 15px auto;"/>'
            else:
                 html += '<p class="alert">‚ö†Ô∏è Plot data is not a valid Matplotlib Figure object.</p>'
        
    # üü¢ NEW: ‡πÄ‡∏û‡∏¥‡πà‡∏° Footer ‡∏Ç‡∏≠‡∏á Report (‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏•‡∏±‡∏á loop for ‡πÅ‡∏•‡∏∞‡πÄ‡∏¢‡∏∑‡πâ‡∏≠‡∏á‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß)
    html += """
    <div class="report-footer">
      &copy; 2025 NTWKKM | Powered by GitHub, Gemini, Streamlit
    </div>
    """
            
    html += "</div></body></html>"
    return html
